# Object Detection Web Application
#### Video Demo:  https://youtu.be/UBxP_5zdRHY?si=f2HUHMFWTy9eEmZZ

#### Description:

This project is an object detection application that can be accessed through the command line and also over the web through a flask application. It utilizes TensorFlow and TensorFlow Hub along with the EfficientDet d7 model. It processes images, detects objects within them, and annotates these objects with bounding boxes and labels.

There are four python files on the root of the project's directory. The project.py file is where the main logic and functions reside. It utilizes tensorflow, tensorflow hub, PIL, and numpy for processing the image and produce the output. It contains a main() function through which the logic can be executed through the command line. The process is this: on the command line you write: python3 project.py <image_path>, where image_path is the path of the image to be processed. The program then loads the Efficientdet d7 pre-trained model from kaggle and passed it along with the image path to the annotate_image() function which produces the processed image. It then saves the image to disk and shows the output image on a new window.

The core of the project.py file is the annotate_image() function, which in turn calls several other functions to process the image. Firstly, it calls the load_image() function which reads the image path with the PIL library and returns the image object. Then it calls the preprocess_image() function which takes the PIL image object, resizes it and converts it into a tensor for processing with the EfficientDet d7 model. After that, the run_detector() function is called to produce the result of the model which includes the coordinates of the bounding boxes, the class ids and the detection scores. The get_class_names() function is used to map the class ids to the actual object names that will be annotated on the output image. Finally, the draw_boxes() function takes these results to produce the output image which has the detected objects wrapped around colored boxes and the name of the objects and the detection scores annotated on each detected object.

The app.py file contains the flask application to access the application logic through the web. I is simple, just have one route and one function that handles both methods: GET and POST, which handles the uploading of the image, the calling of the processing functions on the project.py file and the serving of the processed image. It serves two html files: upload.html, that show the user the button for selecting and uploading the image, and result.html, that show the user the annotated image and a link to redirect the user tothe upload.html file to upload another image. All of the functions that process the input image are imported from the project.py file.

The test_project.py file contains three test functions that checks the expected functionality these three functions from the project.py file: proprocess_image(), get_class_names(), and draw_boxes(). And the labels.py file contains two dictionaries: COCO_LABELS_ENGLISH and COCO_LABELS_SPANISH, which maps the class number to the class labels in english and spanish respectively, and are necessary to map the class numbers produced by the model to the names that should be annotated in the output image.

The project also contains two folders to comlpy with the flask project structure: static/ and templates/. On the static/ folder we have for subfolders: css/, fonts/ (for the output image annotation), images/ (for storing the processed images, sample images and upload images) and js/. On the templates/ folder, there are the two html files served by the flask application: upload.html and result.html. The upload.html just contains the title and two buttons: one for searching the input image, and the other for uploading it and triggering the processing logic. The result.html file is also simple: besides the title, it shows the processed image and a hiperlink to get back to the upload.html file for uploading another image.

Finally, the .gitignore file contains the file and folders that should not be uploaded to github among which is the venv folder that contains the files of of the virtual environment of the project. On the requirements.txt file are the third party libraries necessary for the project which are: tensorflow, tensorflow_hub, numpy, PIL, flask and pytest.

One design choice that I made was to decide on which version of the EfficientDet model to use. Given that it has 7 versions, d1 to d7, on which the d1 version is the faster but the least accurate and the d7 is the slowest but the most accurate and the versions in between range on this two capabilities, I decided to use the d7 version to get a more precisse object detection because I wanted a very accurate model in spite of it takes around two minutes to process the input image.
